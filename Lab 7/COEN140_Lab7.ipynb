{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Ethan Paek\n",
    "\n",
    "Date: 5/13/2020\n",
    "\n",
    "Topic: COEN 140 Lab 7\n",
    "\n",
    "Description: Implement spam classification by using logistic regression\n",
    "\n",
    "Database: www.cse.scu.edu/~yfang/coen140/spambase.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download and import data which is split into a training set (of size 3065) and a test set (of size 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.718</td>\n",
       "      <td>33.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.044</td>\n",
       "      <td>22.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.555</td>\n",
       "      <td>51.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>2.222</td>\n",
       "      <td>23.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.428</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2    3     4    5    6    7     8     9   ...     48     49  \\\n",
       "0  0.0  0.00  0.00  0.0  1.01  0.0  0.0  0.0  0.00  0.00  ...  0.000  0.088   \n",
       "1  0.0  0.00  0.00  0.0  0.00  0.0  0.0  0.0  0.00  0.00  ...  0.098  0.589   \n",
       "2  0.0  0.53  0.00  0.0  1.06  0.0  1.6  0.0  0.00  0.53  ...  0.000  0.239   \n",
       "3  0.0  0.00  0.23  0.0  0.92  0.0  0.0  0.0  0.23  0.00  ...  0.000  0.130   \n",
       "4  0.0  0.00  0.00  0.0  0.00  0.0  0.0  0.0  0.00  0.00  ...  0.000  0.000   \n",
       "\n",
       "      50     51     52     53     54    55     56   57  \n",
       "0  0.000  0.000  0.088  0.000  6.718  33.0  215.0  1.0  \n",
       "1  0.000  0.000  0.000  0.000  2.044  22.0   92.0  1.0  \n",
       "2  0.079  0.159  0.000  0.000  4.555  51.0  123.0  1.0  \n",
       "3  0.026  0.026  0.000  0.026  2.222  23.0  480.0  0.0  \n",
       "4  0.000  0.000  0.000  0.000  1.428   4.0   10.0  0.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and store datasets from website\n",
    "train = pd.read_csv('spambase/spam-train', header=None)\n",
    "test = pd.read_csv('spambase/spam-test', header=None)\n",
    "print(\"Training dataset:\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3065, 57)\n",
      "y_train shape: (3065,)\n"
     ]
    }
   ],
   "source": [
    "# store expected outcomes (last column) into y_train; everything else for prediction goes into X_train\n",
    "X_train = train.drop(57,axis=1)\n",
    "y_train = train[57]\n",
    "\n",
    "# check to make sure we have the correct amount of communities and features\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (1536, 57)\n",
      "y_test shape: (1536,)\n"
     ]
    }
   ],
   "source": [
    "# now do the same thing but for the testing data\n",
    "X_test = test.drop(57,axis=1)\n",
    "y_test = test[57]\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Normalize the features by standardizing the columns so they all have mean 0 and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in a matrix and standardizes it to obtain a mean of 0 and unit variance\n",
    "def standardize(matrix):\n",
    "    standard = (matrix - matrix.mean(axis=0)) / matrix.std(axis=0)\n",
    "    return standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great article that helped me understand standardization: https://builtin.com/data-science/when-and-why-standardize-your-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build and fit a logistic regression model using gradient descent. Report the error rate on the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary to compute sigmoid for logistic function\n",
    "def sigmoid(r):\n",
    "    return 1 / (1 + math.exp(-r))\n",
    "\n",
    "# condense our numpy arrays into one when we use this function\n",
    "v_sigmoid = np.vectorize(sigmoid)\n",
    "\n",
    "alpha = 5*(10e-5)\n",
    "threshold = 10e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_gradient_descent:\n",
    "    \n",
    "    # this function is used to determine our max w through gradient descent for logistic regression\n",
    "    def fit(self, X_train, y_train):\n",
    "        X = X_train.copy()\n",
    "        \n",
    "        # append a column of ones to the end of the training attributes\n",
    "        X['bias'] = np.ones(X.shape[0])\n",
    "        \n",
    "        # generate a Gaussian (normal) distribution for our initial value, based off how many features we have\n",
    "        w0 = np.random.normal(0,1,size=X.shape[1])\n",
    "        \n",
    "        epsilon = 1\n",
    "        # find the max value (w0) with our given cost function\n",
    "        while epsilon > threshold:\n",
    "            w1 = w0 - alpha*(np.dot((v_sigmoid(np.dot(X,w0)) - y_train),X))\n",
    "            epsilon = np.linalg.norm(w1 - w0) # euclidian distance\n",
    "            w0 = w1\n",
    "            \n",
    "        # assign the max value to our class instance\n",
    "        self.w0 = w0\n",
    "        return self\n",
    "    \n",
    "    # calculate our predictions by calculating the sigmoid of our max w and chosen matrix\n",
    "    def predict(self,matrix):\n",
    "        X = matrix.copy()\n",
    "        \n",
    "        # append a column of ones to the end of the testing attributes\n",
    "        X['bias'] = np.ones(X.shape[0])\n",
    "        \n",
    "        # sigmoid to squash outputs to [0,1]\n",
    "        return v_sigmoid(np.dot(self.w0,X.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take raw predictions and round to 0 or 1\n",
    "def round_predictions(prediction_list):\n",
    "    rounded_predictions = []\n",
    "    for item in prediction_list:\n",
    "        # predictions are rounded since 0 = non-spam and 1 = spam\n",
    "        if item < 0.5:\n",
    "            rounded_predictions.append(0)\n",
    "        else:\n",
    "            rounded_predictions.append(1)\n",
    "    return rounded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy by comparing predictions vs actual values\n",
    "def calculate_accuracy(actual, prediction):\n",
    "    n_correct = 0\n",
    "    total = len(y_test)\n",
    "    for i in range(total):\n",
    "        if prediction[i] == actual[i]:\n",
    "            n_correct += 1\n",
    "    accuracy = (n_correct/total) * 100\n",
    "    error = 100 - accuracy\n",
    "    return str(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.logistic_gradient_descent at 0x12124ae50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = logistic_gradient_descent()\n",
    "logistic_regression.fit(standardize(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error with logistic regression and gradient descent: 6.119791666666657%\n",
      "Testing error with logistic regression and gradient descent: 6.966145833333343%\n"
     ]
    }
   ],
   "source": [
    "train_predictions = round_predictions(logistic_regression.predict(standardize(X_train)))\n",
    "print('Training error with logistic regression and gradient descent: ' + calculate_accuracy(y_train, train_predictions) + \"%\")\n",
    "\n",
    "test_predictions = round_predictions(logistic_regression.predict(standardize(X_test)))\n",
    "print('Testing error with logistic regression and gradient descent: ' + calculate_accuracy(y_test, test_predictions) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Rates:\n",
    "\n",
    "Training Error: 6.119791666666657%\n",
    "\n",
    "Testing Error: 6.966145833333343%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
