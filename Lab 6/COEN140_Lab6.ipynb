{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Ethan Paek\n",
    "\n",
    "Date: 5/6/2020\n",
    "\n",
    "Topic: COEN 140 Lab 6\n",
    "\n",
    "Description: Implement Linear Regression and Ridge Regression in Python without using any machine learning libraries on the provided datasets.\n",
    "\n",
    "Training set: http://www.cse.scu.edu/~yfang/coen140/crime-train.txt\n",
    "\n",
    "Testing set: http://www.cse.scu.edu/~yfang/coen140/crime-test.txt\n",
    "\n",
    "A description of the variables: http://www.cse.scu.edu/~yfang/coen140/communities.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>2.10</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViolentCrimesPerPop  population  householdsize  agePct12t21  agePct12t29  \\\n",
       "0                 0.67       -0.45          -1.85        -1.06         0.67   \n",
       "1                 0.43       -0.45          -0.27        -0.22        -0.17   \n",
       "2                 0.12       -0.14           1.87         0.55         0.04   \n",
       "3                 0.03       -0.38           0.53        -0.28        -0.79   \n",
       "4                 0.14       -0.30          -1.12        -0.74        -0.10   \n",
       "\n",
       "   agePct16t24  agePct65up  numbUrban  pctUrban  medIncome  ...  NumStreet  \\\n",
       "0         0.08       -0.85      -0.34      0.68      -0.24  ...      -0.23   \n",
       "1        -0.34       -0.58      -0.50     -1.57      -0.29  ...      -0.23   \n",
       "2         0.02       -1.19      -0.03      0.68       1.05  ...      -0.23   \n",
       "3        -0.64       -0.35      -0.34      0.46       0.66  ...      -0.23   \n",
       "4        -0.40       -0.30      -0.19      0.68       0.76  ...      -0.23   \n",
       "\n",
       "   PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0           -0.02             -0.53           -1.08          -0.13   \n",
       "1           -0.33             -0.58            0.03           0.22   \n",
       "2           -0.11             -1.51            1.07           0.07   \n",
       "3           -0.46              0.54            0.58          -0.08   \n",
       "4            2.10             -0.92           -0.25           0.52   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \n",
       "0           -0.66     -0.41    -0.56            1.26                -0.39  \n",
       "1           -0.46     -0.50    -0.11           -0.62                -0.39  \n",
       "2           -0.01     -0.41     0.77            0.52                -0.39  \n",
       "3           -0.61     -0.23    -0.70           -0.62                -0.39  \n",
       "4           -0.06     -0.50     1.71           -0.27                -0.39  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and store datasets from websites\n",
    "train = pd.read_csv('data/crime-train.txt',delimiter='\\t')\n",
    "test = pd.read_csv('data/crime-test.txt',delimiter='\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1595, 96)\n",
      "y_train shape: (1595, 1)\n"
     ]
    }
   ],
   "source": [
    "# store expected outcomes (1st column) into y_train; everything else for prediction goes into X_train\n",
    "X_train = train.drop('ViolentCrimesPerPop',axis=1)\n",
    "y_train = train['ViolentCrimesPerPop']\n",
    "\n",
    "# we also have to convert values from string to float\n",
    "X_train = np.float64(X_train)\n",
    "\n",
    "# append 1s to the end of X_train as Dr. Fang mentioned in lectures\n",
    "ones = np.ones(len(X_train))\n",
    "X_train = np.column_stack((X_train, ones))\n",
    "\n",
    "y_train = np.float64(y_train)\n",
    "# turn the array into a matrix (with one column)\n",
    "y_train = np.reshape(y_train, (-1,1))\n",
    "\n",
    "# check to make sure we have the correct amount of communities and features\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (399, 96)\n",
      "y_test shape: (399, 1)\n"
     ]
    }
   ],
   "source": [
    "# do the same thing from above but for the testing subset\n",
    "X_test = test.drop('ViolentCrimesPerPop',axis=1)\n",
    "y_test = test['ViolentCrimesPerPop']\n",
    "\n",
    "X_test = np.float64(X_test)\n",
    "\n",
    "ones = np.ones(len(X_test))\n",
    "X_test = np.column_stack((X_test, ones))\n",
    "\n",
    "y_test = np.float64(y_test)\n",
    "# turn the array into a matrix (with one column)\n",
    "y_test = np.reshape(y_test, (-1,1))\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function simply computs the root mean square error (RMSE) by taking in two parameters: the predicted outcome matrix and the actual outcome matrix\n",
    "def RMSE(prediction, actual):\n",
    "    N = len(prediction)\n",
    "    #some sorta issue here\n",
    "    difference = prediction - actual\n",
    "    total = 0\n",
    "    \n",
    "    for instance in difference:\n",
    "        total += (instance ** 2)\n",
    "        \n",
    "    total_error = math.sqrt(total/N)\n",
    "    return total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Perform ridge regression directly using the closed form solution. Use k-fold cross validate (k=5) to select the optimal ùúÜ parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform ridge regression and return list of predicted outcomes that each correspond to their actual values\n",
    "def ridge_regression(x, y, test, lambda_value):\n",
    "    left = np.linalg.inv(np.dot(x.T, x) + (lambda_value * np.identity(len(x.T))))\n",
    "    right = np.dot(x.T, y)\n",
    "    w = np.dot(left, right)\n",
    "    \n",
    "    prediction = []\n",
    "    \n",
    "    for Xtest in test:\n",
    "        prediction.append(np.dot(Xtest.T, w))\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE values:\n",
      " [[0.16031626 0.14530191 0.15755165 0.14669202 0.13770204]\n",
      " [0.1504947  0.13916403 0.14576515 0.13872299 0.12932324]\n",
      " [0.14641669 0.13761947 0.13961026 0.13589421 0.12684322]\n",
      " [0.14511564 0.13746282 0.1363316  0.13498737 0.1268823 ]\n",
      " [0.1449868  0.13758002 0.13455271 0.13464334 0.12781642]\n",
      " [0.14528919 0.13780086 0.13365482 0.13444721 0.12891979]\n",
      " [0.14570088 0.13815894 0.13329282 0.13430567 0.12988101]\n",
      " [0.14610098 0.13865628 0.13324682 0.13421881 0.1306319 ]\n",
      " [0.1464384  0.13923262 0.13336903 0.13420359 0.13119456]\n",
      " [0.14668497 0.13978827 0.13355288 0.13425675 0.13159847]] \n",
      "\n",
      "ùúÜ = 400.0 : 0.14951277619075795\n",
      "ùúÜ = 200.0 : 0.14069401845317783\n",
      "ùúÜ = 100.0 : 0.13727677223186574\n",
      "ùúÜ = 50.0 : 0.1361559439275552\n",
      "ùúÜ = 25.0 : 0.13591585919851984\n",
      "ùúÜ = 12.5 : 0.13602237446230686\n",
      "ùúÜ = 6.25 : 0.13626786494076748\n",
      "ùúÜ = 3.125 : 0.13657095693642846\n",
      "ùúÜ = 1.5625 : 0.1368876407319742\n",
      "ùúÜ = 0.78125 : 0.13717626806866692\n",
      "\n",
      "The optimal ùúÜ is: 25.0\n",
      "Training RMSE for ridge regression using gradient descent is 0.13591585919851984\n"
     ]
    }
   ],
   "source": [
    "lambda_value = 400\n",
    "RMSEs = np.zeros((10,5))\n",
    "minimum = 0\n",
    "\n",
    "# do k-fold cross validation with k = 5\n",
    "for segment in range(len(RMSEs)):\n",
    "    for k in range(5):\n",
    "        # train with 4/5 of our dataset\n",
    "        X_train_k = np.concatenate((X_train[0:int(k*(len(X_train)/5))], X_train[int((k+1)*(len(X_train)/5)):int(len(X_train))]))\n",
    "        y_train_k = np.concatenate((y_train[0:int(k*(len(y_train)/5))], y_train[int((k+1)*(len(y_train)/5)):int(len(y_train))]))\n",
    "        \n",
    "        # use the remaining 1/5 dataset to validate our results\n",
    "        X_validate_k = X_train[int(k*(len(X_train)/5)):int((k+1)*(len(X_train)/5))]\n",
    "        y_validate_k = y_train[int(k*(len(y_train)/5)):int((k+1)*(len(y_train)/5))]\n",
    "\n",
    "        # perform ridge regression on each fold and each lambda \n",
    "        prediction = ridge_regression(X_train_k, y_train_k, X_validate_k, lambda_value)\n",
    "\n",
    "        # for each lambda, put all 5 of the different RMSEs on the same row\n",
    "        RMSEs[segment, k] = RMSE(prediction, y_validate_k)\n",
    "        \n",
    "    lambda_value /= 2\n",
    "\n",
    "print(\"RMSE values:\\n\",RMSEs, \"\\n\")\n",
    "    \n",
    "# get average RMSE for each lambda and choose optimal lambda\n",
    "for i in range(len(RMSEs)-1):\n",
    "    if (sum(RMSEs[i+1]) / 5) < (sum(RMSEs[minimum]) / 5):\n",
    "        minimum = i+1\n",
    "\n",
    "for j in range(len(RMSEs)):\n",
    "    print(\"ùúÜ =\", (400 / (2 ** j)), \":\", sum(RMSEs[j]) / 5)\n",
    "\n",
    "optimal_lambda = 400 / (2 ** minimum)\n",
    "\n",
    "print(\"\\nThe optimal ùúÜ is:\", optimal_lambda)\n",
    "print(\"Training RMSE for ridge regression using closed form solution is\", (sum(RMSEs[minimum]) / 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the best ùúÜ = 25, since the average RMSE for this value is lower than all other tested lambdas. In other words, the RMSE is minimized when the lambda is equal to 25 as opposed to any other lambda where ùúÜ=400/(2^n) and 0 < n < 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Perform linear regression using the gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss function for linear regression\n",
    "def linear_gradient_descent(x, y, w):\n",
    "    left = (y - np.dot(x, w)).T\n",
    "    right = (y - np.dot(x, w))\n",
    "    min_w = np.dot(left, right)\n",
    "    return min_w\n",
    "\n",
    "alpha = 5*(10**-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-efcd7add2699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mL0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# generate a Gaussian (normal) distribution for our initial value, based off how many features we have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mw0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mL0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# use gradient descent until convergence to obtain w\n",
    "L1 = 1\n",
    "L0 = 0\n",
    "# generate a Gaussian (normal) distribution for our initial value, based off how many features we have\n",
    "w0 = np.random.normal(0, 1, (X_train.shape[1],1))\n",
    "\n",
    "while (abs(L1 - L0) > (10**-5)):\n",
    "    w1 = w0 - (alpha * np.dot(X_train.T, (np.dot(X_train, w0) - y_train)))\n",
    "    L0 = linear_gradient_descent(X_train, y_train, w0)\n",
    "    L1 = linear_gradient_descent(X_train, y_train, w1)\n",
    "    w0 = w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in an NxK array and returns predictions in the form of an Nx1 array\n",
    "def problem2(w_value, matrix):\n",
    "    prediction = []\n",
    "    for x in matrix:\n",
    "        prediction.append(np.dot(w_value.T, x))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE for linear regression using gradient descent is 0.1279001630206582\n",
      "Testing RMSE for linear regression using gradient descent is 0.145836802702037\n"
     ]
    }
   ],
   "source": [
    "train_prediction = []\n",
    "test_prediction = []\n",
    "\n",
    "# make predictions and calculate RMSE for training data\n",
    "train_prediction = problem2(w0, X_train)\n",
    "\n",
    "train_linear_RSME = RMSE(train_prediction, y_train)\n",
    "print(\"Training RMSE for linear regression using gradient descent is\", train_linear_RSME)\n",
    "\n",
    "# make predictions and calculate RMSE for test data\n",
    "test_prediction = problem2(w0, X_test)\n",
    "\n",
    "test_linear_RMSE = RMSE(test_prediction, y_test)\n",
    "print(\"Testing RMSE for linear regression using gradient descent is\", test_linear_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Error Rates\n",
    "\n",
    "#### Lab 5\n",
    "\n",
    "Training: 0.12768967421762187\n",
    "\n",
    "Testing: 0.14583464490949133\n",
    "\n",
    "#### Lab 6\n",
    "\n",
    "Training: 0.1279001630206582\n",
    "\n",
    "Testing: 0.145836802702037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Perform ridge regression with 5-fold cross validation using the gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss function for ridge regression\n",
    "def ridge_gradient_descent(x, y, w, lambda_value):\n",
    "    left = (y - np.dot(x, w)).T\n",
    "    right = (y - np.dot(x, w))\n",
    "    min_W = np.dot(left, right) + (optimal_lambda * np.dot(w0.T, w0))\n",
    "    \n",
    "    return min_W\n",
    "\n",
    "alpha = 5*(10**-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in an NxK array and returns predictions in the form of an Nx1 array\n",
    "def problem3(w, validation):\n",
    "    predictions = []\n",
    "    for Xnew in validation:\n",
    "        predictions.append(np.dot(w.T, Xnew))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE values:\n",
      " [[0.16031645 0.14529659 0.15774393 0.14644346 0.1377206 ]\n",
      " [0.15041878 0.1391562  0.14576057 0.13872718 0.12955656]\n",
      " [0.14656764 0.13754041 0.1395291  0.13588014 0.12684171]\n",
      " [0.14511777 0.13735984 0.13693394 0.13483061 0.12691422]\n",
      " [0.1452592  0.1377219  0.13455798 0.13468397 0.1277978 ]\n",
      " [0.14502404 0.13841093 0.1335924  0.1344487  0.12898442]\n",
      " [0.14565418 0.13805621 0.13335367 0.13425258 0.12989125]\n",
      " [0.14623778 0.13838639 0.13314707 0.13455596 0.13030709]\n",
      " [0.14633717 0.13909454 0.134029   0.13433102 0.13090378]\n",
      " [0.1473196  0.14070872 0.13445381 0.13625563 0.1326497 ]] \n",
      "\n",
      "ùúÜ = 400.0 : 0.1495042067724742\n",
      "ùúÜ = 200.0 : 0.1407238583845988\n",
      "ùúÜ = 100.0 : 0.13727179980315438\n",
      "ùúÜ = 50.0 : 0.136231274312913\n",
      "ùúÜ = 25.0 : 0.13600416890273567\n",
      "ùúÜ = 12.5 : 0.1360920985283161\n",
      "ùúÜ = 6.25 : 0.13624157733562461\n",
      "ùúÜ = 3.125 : 0.13652685691040173\n",
      "ùúÜ = 1.5625 : 0.1369391002923243\n",
      "ùúÜ = 0.78125 : 0.13827749133112024\n",
      "\n",
      "The optimal ùúÜ is: 25.0\n",
      "Training RMSE for ridge regression using gradient descent is 0.13600416890273567\n"
     ]
    }
   ],
   "source": [
    "# similar to problem 1, we need to find the optimal lambda\n",
    "lambda_value = 400\n",
    "RMSEs = np.zeros((10,5))\n",
    "minimum = 0\n",
    "\n",
    "# do k-fold cross validation with k = 5\n",
    "for segment in range(len(RMSEs)):\n",
    "    for k in range(5):\n",
    "        # train with 4/5 of our dataset\n",
    "        X_train_k = np.concatenate((X_train[0:int(k*(len(X_train)/5))], X_train[int((k+1)*(len(X_train)/5)):int(len(X_train))]))\n",
    "        y_train_k = np.concatenate((y_train[0:int(k*(len(y_train)/5))], y_train[int((k+1)*(len(y_train)/5)):int(len(y_train))]))\n",
    "        \n",
    "        # use the remaining 1/5 dataset to validate our results\n",
    "        X_validate_k = X_train[int(k*(len(X_train)/5)):int((k+1)*(len(X_train)/5))]\n",
    "        y_validate_k = y_train[int(k*(len(y_train)/5)):int((k+1)*(len(y_train)/5))]\n",
    "        \n",
    "        # perform ridge regression using gradient descent on each fold and each lambda\n",
    "        L1 = 1\n",
    "        L0 = 0\n",
    "        # generate a Gaussian (normal) distribution for our initial value, based off how many features we have\n",
    "        w0 = np.random.normal(0, 1, (X_train.shape[1],1))\n",
    "        while (abs(L1 - L0) > (10**-5)):\n",
    "            w1 = w0 - (alpha * (np.dot(X_train_k.T, (np.dot(X_train_k, w0) - y_train_k)) + (lambda_value * w0)))\n",
    "            L0 = ridge_gradient_descent(X_train_k, y_train_k, w0, lambda_value)\n",
    "            L1 = ridge_gradient_descent(X_train_k, y_train_k, w1, lambda_value)\n",
    "            w0 = w1\n",
    "        \n",
    "        validated_results = []\n",
    "        validated_results = problem3(w0, X_validate_k)\n",
    "\n",
    "        # for each lambda, put all 5 of the different RMSEs on the same row\n",
    "        RMSEs[segment, k] = RMSE(validated_results, y_validate_k)\n",
    "        \n",
    "    lambda_value /= 2\n",
    "\n",
    "print(\"RMSE values:\\n\",RMSEs, \"\\n\")\n",
    "    \n",
    "# get average RMSE for each lambda and choose optimal lambda\n",
    "for i in range(len(RMSEs)-1):\n",
    "    if (sum(RMSEs[i+1]) / 5) < (sum(RMSEs[minimum]) / 5):\n",
    "        minimum = i+1\n",
    "\n",
    "for j in range(len(RMSEs)):\n",
    "    print(\"ùúÜ =\", (400 / (2 ** j)), \":\", sum(RMSEs[j]) / 5)\n",
    "\n",
    "optimal_lambda = 400 / (2 ** minimum)\n",
    "\n",
    "print(\"\\nThe optimal ùúÜ is:\", optimal_lambda)\n",
    "print(\"Training RMSE for ridge regression using gradient descent is\", (sum(RMSEs[minimum]) / 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RMSE for ridge regression using gradient descent is 0.14550739450917766\n"
     ]
    }
   ],
   "source": [
    "# re-compute w0 with the optimal lambda and all data from training subset so we can get results for our testing subset\n",
    "L1 = 1\n",
    "L0 = 0\n",
    "# generate a Gaussian (normal) distribution for our initial value, based off how many features we have\n",
    "w0 = np.random.normal(0, 1, (X_train.shape[1],1))\n",
    "while (abs(L1 - L0) > (10**-5)):\n",
    "    w1 = w0 - (alpha * (np.dot(X_train.T, (np.dot(X_train, w0) - y_train)) + (optimal_lambda * w0)))\n",
    "    L0 = ridge_gradient_descent(X_train, y_train, w0, lambda_value)\n",
    "    L1 = ridge_gradient_descent(X_train, y_train, w1, lambda_value)\n",
    "    w0 = w1\n",
    "\n",
    "test_predictions = []\n",
    "test_predictions = problem3(w0, X_test)\n",
    "\n",
    "test_ridge_RMSE = RMSE(test_predictions, y_test)\n",
    "print(\"Testing RMSE for ridge regression using gradient descent is\", test_ridge_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE Values for Problem 3\n",
    "\n",
    "Training: 0.13600416890273567\n",
    "\n",
    "Testing: 0.14550739450917766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
